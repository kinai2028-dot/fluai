import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import json
import traceback

# è®¾å®šé¡µé¢é…ç½®
st.set_page_config(
    page_title="Flux AI å›¾åƒç”Ÿæˆå™¨ Pro", 
    page_icon="ğŸ¨", 
    layout="wide"
)

# å¢å¼ºçš„é”™è¯¯å¤„ç†ç±»
class FluxAPIErrorHandler:
    def __init__(self):
        self.error_patterns = {
            'provider_500': {
                'keywords': ['unexpected provider error', '500', 'internal server error'],
                'type': 'provider_error',
                'severity': 'high',
                'retry_recommended': True,
                'solutions': [
                    'æœåŠ¡å™¨ä¸´æ—¶æ•…éšœï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é‡è¯•',
                    'å°è¯•åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨æ¨¡å‹',
                    'ç®€åŒ–æç¤ºè¯å†…å®¹',
                    'æ£€æŸ¥ API æä¾›å•†æœåŠ¡çŠ¶æ€'
                ]
            },
            'auth_error': {
                'keywords': ['401', '403', 'unauthorized', 'forbidden', 'invalid api key', 'authentication'],
                'type': 'authentication',
                'severity': 'critical',
                'retry_recommended': False,
                'solutions': [
                    'æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®',
                    'éªŒè¯è´¦æˆ·æƒé™å’Œä½™é¢',
                    'ç¡®è®¤ API ç«¯ç‚¹é…ç½®',
                    'é‡æ–°ç”Ÿæˆ API å¯†é’¥'
                ]
            },
            'rate_limit': {
                'keywords': ['429', 'rate limit', 'too many requests', 'quota exceeded'],
                'type': 'rate_limiting',
                'severity': 'medium',
                'retry_recommended': True,
                'solutions': [
                    'è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œæ­£åœ¨ç­‰å¾…é‡è¯•',
                    'è€ƒè™‘å‡å°‘å¹¶å‘è¯·æ±‚',
                    'å‡çº§åˆ°æ›´é«˜çº§åˆ«çš„ API è®¡åˆ’',
                    'ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥'
                ]
            },
            'model_error': {
                'keywords': ['404', 'model not found', 'invalid model', 'model does not exist'],
                'type': 'model_unavailable',
                'severity': 'high',
                'retry_recommended': False,
                'solutions': [
                    'é€‰æ‹©çš„æ¨¡å‹ä¸å¯ç”¨',
                    'åˆ‡æ¢åˆ°å·²éªŒè¯çš„å¯ç”¨æ¨¡å‹',
                    'æ£€æŸ¥æ¨¡å‹åç§°æ‹¼å†™',
                    'è”ç³» API æä¾›å•†ç¡®è®¤æ¨¡å‹çŠ¶æ€'
                ]
            },
            'network_error': {
                'keywords': ['timeout', 'connection', 'network', 'dns', 'ssl', 'certificate'],
                'type': 'network_issue',
                'severity': 'medium',
                'retry_recommended': True,
                'solutions': [
                    'ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ­£åœ¨é‡è¯•',
                    'æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§',
                    'å°è¯•æ›´æ¢ç½‘ç»œç¯å¢ƒ',
                    'æ£€æŸ¥é˜²ç«å¢™å’Œä»£ç†è®¾ç½®'
                ]
            },
            'parameter_error': {
                'keywords': ['invalid parameter', 'bad request', '400', 'validation error', 'malformed'],
                'type': 'parameter_invalid',
                'severity': 'high',
                'retry_recommended': False,
                'solutions': [
                    'è¯·æ±‚å‚æ•°æ— æ•ˆ',
                    'æ£€æŸ¥å›¾åƒå°ºå¯¸è®¾ç½®',
                    'éªŒè¯æç¤ºè¯æ ¼å¼',
                    'ç¡®è®¤ç”Ÿæˆæ•°é‡åœ¨å…è®¸èŒƒå›´å†…'
                ]
            },
            'content_policy': {
                'keywords': ['content policy', 'inappropriate', 'unsafe', 'filtered', 'blocked'],
                'type': 'content_violation',
                'severity': 'medium',
                'retry_recommended': False,
                'solutions': [
                    'æç¤ºè¯è¿åå†…å®¹æ”¿ç­–',
                    'ä¿®æ”¹æç¤ºè¯é¿å…æ•æ„Ÿå†…å®¹',
                    'ä½¿ç”¨æ›´æ¸©å’Œçš„æè¿°',
                    'å‚è€ƒå¹³å°ä½¿ç”¨æŒ‡å—'
                ]
            },
            'openai_client_error': {
                'keywords': ['openai', 'client error', 'initialization failed', 'api client'],
                'type': 'client_initialization',
                'severity': 'critical',
                'retry_recommended': False,
                'solutions': [
                    'OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥',
                    'æ£€æŸ¥ API å¯†é’¥æ ¼å¼',
                    'éªŒè¯ API ç«¯ç‚¹ URL',
                    'é‡æ–°é…ç½® API è®¾ç½®'
                ]
            }
        }
    
    def analyze_error(self, error_msg: str, context: Dict = None) -> Dict:
        """åˆ†æé”™è¯¯å¹¶æä¾›è¯¦ç»†è¯Šæ–­ - å¢å¼ºç‰ˆæœ¬"""
        if not isinstance(error_msg, str):
            error_msg = str(error_msg)
        
        error_msg_lower = error_msg.lower()
        
        # è®°å½•åŸå§‹é”™è¯¯å’Œä¸Šä¸‹æ–‡
        analysis_result = {
            'pattern': 'unknown',
            'type': 'unknown_error',
            'severity': 'medium',
            'retry_recommended': True,
            'solutions': ['å°è¯•é‡æ–°ç”Ÿæˆ', 'æ£€æŸ¥é…ç½®è®¾ç½®'],
            'original_error': error_msg[:1000],
            'context': context or {},
            'analysis_timestamp': datetime.datetime.now().isoformat()
        }
        
        # æœç´¢åŒ¹é…çš„é”™è¯¯æ¨¡å¼
        for pattern_name, pattern_info in self.error_patterns.items():
            try:
                keywords = pattern_info.get('keywords', [])
                if any(keyword in error_msg_lower for keyword in keywords):
                    analysis_result.update({
                        'pattern': pattern_name,
                        'type': pattern_info.get('type', 'unknown'),
                        'severity': pattern_info.get('severity', 'medium'),
                        'retry_recommended': pattern_info.get('retry_recommended', True),
                        'solutions': pattern_info.get('solutions', ['å°è¯•é‡æ–°ç”Ÿæˆ']),
                        'matched_keywords': [kw for kw in keywords if kw in error_msg_lower]
                    })
                    st.info(f"ğŸ” åŒ¹é…åˆ°é”™è¯¯æ¨¡å¼: {pattern_name}")
                    return analysis_result
                    
            except Exception as match_error:
                st.warning(f"é”™è¯¯æ¨¡å¼åŒ¹é…å¤±è´¥ ({pattern_name}): {str(match_error)}")
                continue
        
        # ç‰¹æ®Šé”™è¯¯æ£€æµ‹
        if 'unexpected error in retry loop' in error_msg_lower:
            analysis_result.update({
                'pattern': 'retry_loop_error',
                'type': 'retry_mechanism_failure',
                'severity': 'high',
                'retry_recommended': False,
                'solutions': [
                    'é‡è¯•æœºåˆ¶æœ¬èº«å‡ºç°é—®é¢˜',
                    'é‡ç½®é”™è¯¯çŠ¶æ€å’Œå®¢æˆ·ç«¯',
                    'åˆ‡æ¢åˆ°æœ€ç¨³å®šçš„æ¨¡å‹',
                    'å‡å°‘ç”Ÿæˆå¤æ‚åº¦'
                ]
            })
        
        st.warning(f"âš ï¸ æœªè¯†åˆ«çš„é”™è¯¯æ¨¡å¼: {error_msg[:100]}...")
        return analysis_result

# å¢å¼ºçš„ API å®¢æˆ·ç«¯ç±»
class ResilientFluxClient:
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.client = None
        self.initialization_error = None
        
        try:
            self.client = OpenAI(api_key=api_key, base_url=base_url)
            st.success("âœ… OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.initialization_error = str(e)
            st.error(f"âŒ OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            
        self.error_handler = FluxAPIErrorHandler()
        self.session_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'retry_attempts': 0,
            'error_types': {},
            'last_errors': []
        }
    
    def validate_parameters(self, **params) -> Tuple[bool, str]:
        """éªŒè¯ç”Ÿæˆå‚æ•°"""
        try:
            model = params.get('model')
            prompt = params.get('prompt', '')
            n = params.get('n', 1)
            size = params.get('size', '1024x1024')
            
            # æ£€æŸ¥å¿…éœ€å‚æ•°
            if not model:
                return False, "ç¼ºå°‘æ¨¡å‹å‚æ•°"
            
            if not prompt or len(prompt.strip()) == 0:
                return False, "æç¤ºè¯ä¸èƒ½ä¸ºç©º"
            
            if len(prompt) > 4000:
                return False, "æç¤ºè¯è¿‡é•¿ï¼Œè¯·ç¼©çŸ­è‡³4000å­—ç¬¦ä»¥å†…"
            
            # æ£€æŸ¥æ•°é‡
            if not isinstance(n, int) or n < 1 or n > 4:
                return False, "ç”Ÿæˆæ•°é‡å¿…é¡»åœ¨1-4ä¹‹é—´"
            
            # æ£€æŸ¥å°ºå¯¸æ ¼å¼
            valid_sizes = ['1024x1024', '1152x896', '896x1152', '1344x768', '768x1344']
            if size not in valid_sizes:
                return False, f"æ— æ•ˆçš„å›¾åƒå°ºå¯¸ï¼Œæ”¯æŒ: {', '.join(valid_sizes)}"
            
            return True, "å‚æ•°éªŒè¯é€šè¿‡"
            
        except Exception as e:
            return False, f"å‚æ•°éªŒè¯é”™è¯¯: {str(e)}"
    
    def log_error(self, error_type: str, error_msg: str, attempt: int, model: str):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        try:
            error_entry = {
                'timestamp': datetime.datetime.now().isoformat(),
                'type': error_type,
                'message': error_msg[:500],  # é™åˆ¶é•¿åº¦
                'attempt': attempt,
                'model': model
            }
            
            self.session_stats['last_errors'].append(error_entry)
            
            # åªä¿ç•™æœ€è¿‘10ä¸ªé”™è¯¯
            if len(self.session_stats['last_errors']) > 10:
                self.session_stats['last_errors'] = self.session_stats['last_errors'][-10:]
            
            # æ›´æ–°é”™è¯¯ç±»å‹ç»Ÿè®¡
            if error_type in self.session_stats['error_types']:
                self.session_stats['error_types'][error_type] += 1
            else:
                self.session_stats['error_types'][error_type] = 1
                
        except Exception as log_error:
            st.warning(f"è®°å½•é”™è¯¯ä¿¡æ¯å¤±è´¥: {str(log_error)}")
    
    def generate_with_resilience(self, **params) -> Tuple[bool, any, Dict]:
        """
        å…·æœ‰å¼¹æ€§çš„å›¾åƒç”Ÿæˆæ–¹æ³• - å®Œå…¨é‡å†™
        """
        # åˆå§‹æ£€æŸ¥
        if self.client is None:
            error_result = {
                'type': 'client_initialization',
                'severity': 'critical',
                'retry_recommended': False,
                'solutions': ['é‡æ–°é…ç½® API å®¢æˆ·ç«¯', 'æ£€æŸ¥ API å¯†é’¥å’Œç«¯ç‚¹'],
                'original_error': self.initialization_error or 'OpenAI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–'
            }
            return False, error_result, {'status': 'failed', 'attempts': 0, 'error_type': 'client_init'}
        
        # å‚æ•°éªŒè¯
        param_valid, param_msg = self.validate_parameters(**params)
        if not param_valid:
            error_result = {
                'type': 'parameter_invalid',
                'severity': 'high',
                'retry_recommended': False,
                'solutions': [f'å‚æ•°éªŒè¯å¤±è´¥: {param_msg}', 'æ£€æŸ¥è¾“å…¥å‚æ•°', 'ä½¿ç”¨æ¨èçš„å‚æ•°è®¾ç½®'],
                'original_error': param_msg
            }
            return False, error_result, {'status': 'failed', 'attempts': 0, 'error_type': 'param_validation'}
        
        # è®¾ç½®é‡è¯•å‚æ•°
        max_retries = 3
        base_delay = 2
        fallback_models = ['flux.1-schnell', 'flux.1-krea-dev', 'flux.1.1-pro']
        original_model = params.get('model', 'flux.1-schnell')
        current_params = params.copy()
        
        # æ›´æ–°ç»Ÿè®¡
        self.session_stats['total_requests'] += 1
        
        st.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆ: æ¨¡å‹={original_model}, æç¤ºè¯é•¿åº¦={len(params.get('prompt', ''))}")
        
        # é‡è¯•å¾ªç¯
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    self.session_stats['retry_attempts'] += 1
                    st.info(f"ğŸ”„ ç¬¬ {attempt + 1}/{max_retries} æ¬¡é‡è¯•...")
                
                # æ˜¾ç¤ºå½“å‰å‚æ•°
                with st.expander(f"ğŸ“‹ ç¬¬ {attempt + 1} æ¬¡å°è¯•å‚æ•°"):
                    st.json({
                        'model': current_params.get('model'),
                        'prompt_length': len(current_params.get('prompt', '')),
                        'n': current_params.get('n'),
                        'size': current_params.get('size')
                    })
                
                # æ‰§è¡Œç”Ÿæˆ
                st.info(f"ğŸ“¡ è°ƒç”¨ API...")
                response = self.client.images.generate(**current_params)
                
                # æˆåŠŸå¤„ç†
                self.session_stats['successful_requests'] += 1
                st.success(f"âœ… ç”ŸæˆæˆåŠŸ! (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                
                return True, response, {
                    'status': 'success',
                    'attempts': attempt + 1,
                    'model_used': current_params.get('model'),
                    'message': f'æˆåŠŸç”Ÿæˆ (å°è¯• {attempt + 1}/{max_retries})',
                    'final_params': current_params
                }
                
            except Exception as e:
                error_msg = str(e)
                error_context = {
                    'attempt': attempt + 1,
                    'max_retries': max_retries,
                    'model': current_params.get('model'),
                    'params': {k: v for k, v in current_params.items() if k != 'prompt'}  # ä¸è®°å½•å®Œæ•´æç¤ºè¯
                }
                
                # è®°å½•é”™è¯¯
                self.log_error('generation_error', error_msg, attempt + 1, current_params.get('model'))
                
                # åˆ†æé”™è¯¯
                error_analysis = self.error_handler.analyze_error(error_msg, error_context)
                
                st.error(f"âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {error_analysis.get('type', 'unknown')}")
                st.code(f"é”™è¯¯è¯¦æƒ…: {error_msg[:200]}...")
                
                # å†³å®šæ˜¯å¦ç»§ç»­é‡è¯•
                if attempt >= max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    st.error("ğŸ’¥ æ‰€æœ‰é‡è¯•å°è¯•å‡å·²å¤±è´¥")
                    self.session_stats['failed_requests'] += 1
                    
                    return False, error_analysis, {
                        'status': 'failed',
                        'attempts': max_retries,
                        'error_type': error_analysis.get('type'),
                        'message': 'è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°',
                        'all_errors': self.session_stats['last_errors'][-max_retries:]
                    }
                
                # æ ¹æ®é”™è¯¯ç±»å‹å†³å®šé‡è¯•ç­–ç•¥
                pattern = error_analysis.get('pattern', 'unknown')
                
                if pattern == 'provider_500':
                    # 500é”™è¯¯ - æŒ‡æ•°é€€é¿é‡è¯•
                    delay = base_delay * (2 ** attempt) + random.uniform(1, 3)
                    st.warning(f"ğŸ”„ æ£€æµ‹åˆ°æœåŠ¡å™¨é”™è¯¯ï¼Œ{delay:.1f} ç§’åé‡è¯•...")
                    
                    progress_bar = st.progress(0)
                    for i in range(int(delay * 2)):  # æ›´ç»†ç²’åº¦çš„è¿›åº¦
                        progress_bar.progress((i + 1) / (delay * 2))
                        time.sleep(0.5)
                    progress_bar.empty()
                    continue
                
                elif pattern == 'model_error' and attempt < max_retries - 1:
                    # æ¨¡å‹é”™è¯¯ - å°è¯•å›é€€æ¨¡å‹
                    current_model = current_params.get('model')
                    available_fallbacks = [m for m in fallback_models if m != current_model]
                    
                    if available_fallbacks:
                        fallback_model = available_fallbacks[0]
                        current_params['model'] = fallback_model
                        st.info(f"ğŸ¯ å°è¯•å›é€€æ¨¡å‹: {current_model} â†’ {fallback_model}")
                        continue
                    else:
                        st.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å›é€€æ¨¡å‹")
                
                elif pattern == 'rate_limit':
                    # é€Ÿç‡é™åˆ¶ - é•¿å»¶è¿Ÿé‡è¯•
                    delay = base_delay * (4 ** attempt) + random.uniform(5, 10)
                    st.warning(f"ğŸš¦ é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œ{delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    continue
                
                elif pattern == 'parameter_error':
                    # å‚æ•°é”™è¯¯ - å°è¯•ç®€åŒ–å‚æ•°
                    if current_params.get('n', 1) > 1:
                        current_params['n'] = 1
                        st.info("ğŸ”§ ç®€åŒ–å‚æ•°: å‡å°‘ç”Ÿæˆæ•°é‡åˆ°1")
                        continue
                    elif current_params.get('size') != '1024x1024':
                        current_params['size'] = '1024x1024'
                        st.info("ğŸ”§ ç®€åŒ–å‚æ•°: ä½¿ç”¨æ ‡å‡†å°ºå¯¸")
                        continue
                
                elif not error_analysis.get('retry_recommended', True):
                    # ä¸å»ºè®®é‡è¯•çš„é”™è¯¯
                    st.error("ğŸ›‘ æ£€æµ‹åˆ°ä¸é€‚åˆé‡è¯•çš„é”™è¯¯")
                    self.session_stats['failed_requests'] += 1
                    
                    return False, error_analysis, {
                        'status': 'failed',
                        'attempts': attempt + 1,
                        'error_type': error_analysis.get('type'),
                        'no_retry_reason': 'é”™è¯¯ç±»å‹ä¸é€‚åˆé‡è¯•'
                    }
                
                # é»˜è®¤é‡è¯•ç­–ç•¥
                delay = base_delay * (1.5 ** attempt) + random.uniform(0, 2)
                st.info(f"â³ {delay:.1f} ç§’åè¿›è¡Œé»˜è®¤é‡è¯•...")
                time.sleep(delay)
                continue
        
        # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸä½†æ²¡æœ‰è¿”å›ï¼Œè¿™æ˜¯ä¸€ä¸ªæ„å¤–æƒ…å†µ
        st.error("ğŸš¨ é‡è¯•å¾ªç¯æ„å¤–ç»“æŸ - è¿™ä¸åº”è¯¥å‘ç”Ÿ")
        
        # åˆ›å»ºè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š
        error_analysis = {
            'pattern': 'retry_loop_completion',
            'type': 'unexpected_loop_completion',
            'severity': 'critical',
            'retry_recommended': False,
            'solutions': [
                'é‡è¯•å¾ªç¯æ„å¤–å®Œæˆ',
                'é‡ç½®å®¢æˆ·ç«¯çŠ¶æ€',
                'æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—',
                'è”ç³»æŠ€æœ¯æ”¯æŒ'
            ],
            'original_error': 'Retry loop completed without return',
            'context': {
                'max_retries': max_retries,
                'final_params': current_params,
                'error_history': self.session_stats['last_errors'][-max_retries:]
            }
        }
        
        self.session_stats['failed_requests'] += 1
        
        return False, error_analysis, {
            'status': 'failed',
            'attempts': max_retries,
            'error_type': 'loop_completion_error',
            'message': 'é‡è¯•å¾ªç¯æ„å¤–å®Œæˆ'
        }

def show_error_recovery_panel(error_analysis: Dict, diagnostic_info: Dict):
    """æ˜¾ç¤ºé”™è¯¯æ¢å¤é¢æ¿ - å¢å¼ºç‰ˆæœ¬"""
    st.subheader("ğŸš¨ è¯¦ç»†é”™è¯¯è¯Šæ–­")
    
    # é”™è¯¯æ¦‚è§ˆ
    error_type = error_analysis.get('type', 'unknown_error')
    severity = error_analysis.get('severity', 'medium')
    pattern = error_analysis.get('pattern', 'unknown')
    
    # åŸºæœ¬ä¿¡æ¯æ˜¾ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        severity_colors = {
            'critical': ('ğŸ”´', 'red'),
            'high': ('ğŸŸ ', 'orange'), 
            'medium': ('ğŸŸ¡', 'yellow'),
            'low': ('ğŸŸ¢', 'green')
        }
        icon, color = severity_colors.get(severity, ('â“', 'gray'))
        st.metric("ä¸¥é‡ç¨‹åº¦", f"{icon} {severity.upper()}")
    
    with col2:
        st.metric("é”™è¯¯ç±»å‹", error_type.replace('_', ' ').title())
    
    with col3:
        st.metric("é”™è¯¯æ¨¡å¼", pattern.replace('_', ' ').title())
    
    with col4:
        attempts = diagnostic_info.get('attempts', 'N/A')
        st.metric("å°è¯•æ¬¡æ•°", str(attempts))
    
    # è¯¦ç»†é”™è¯¯ä¿¡æ¯
    with st.expander("ğŸ” å®Œæ•´é”™è¯¯è¯¦æƒ…", expanded=False):
        st.markdown("### åŸå§‹é”™è¯¯æ¶ˆæ¯")
        original_error = error_analysis.get('original_error', 'æœªçŸ¥é”™è¯¯')
        st.code(original_error)
        
        st.markdown("### é”™è¯¯ä¸Šä¸‹æ–‡")
        context = error_analysis.get('context', {})
        if context:
            st.json(context)
        else:
            st.info("æ— é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯")
        
        st.markdown("### è¯Šæ–­ä¿¡æ¯")
        st.json(diagnostic_info)
        
        # åŒ¹é…çš„å…³é”®è¯
        matched_keywords = error_analysis.get('matched_keywords', [])
        if matched_keywords:
            st.markdown("### åŒ¹é…çš„é”™è¯¯å…³é”®è¯")
            st.write(", ".join(matched_keywords))
    
    # è§£å†³æ–¹æ¡ˆ
    st.subheader("ğŸ’¡ æ¨èè§£å†³æ–¹æ¡ˆ")
    solutions = error_analysis.get('solutions', ['å°è¯•é‡æ–°ç”Ÿæˆ'])
    
    for i, solution in enumerate(solutions, 1):
        if i == 1:
            st.success(f"**ğŸ¯ é¦–é€‰æ–¹æ¡ˆ:** {solution}")
        else:
            st.info(f"**{i}.** {solution}")
    
    # å¿«é€Ÿä¿®å¤æ“ä½œ
    st.subheader("âš¡ å¿«é€Ÿä¿®å¤æ“ä½œ")
    
    col_fix1, col_fix2, col_fix3, col_fix4 = st.columns(4)
    
    with col_fix1:
        if st.button("ğŸ”„ ç«‹å³é‡è¯•", use_container_width=True, type="primary"):
            st.session_state.retry_generation = True
            st.success("å‡†å¤‡é‡è¯•...")
            st.rerun()
    
    with col_fix2:
        if st.button("ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼", use_container_width=True):
            # è®¾ç½®æœ€å®‰å…¨çš„å‚æ•°
            st.session_state.safe_mode_params = {
                'model': 'flux.1-schnell',
                'size': '1024x1024',
                'n': 1
            }
            st.success("å·²å¯ç”¨å®‰å…¨æ¨¡å¼")
            st.rerun()
    
    with col_fix3:
        if st.button("ğŸ”§ é‡ç½®å®¢æˆ·ç«¯", use_container_width=True):
            # é‡ç½®å®¢æˆ·ç«¯çŠ¶æ€
            if 'resilient_client' in st.session_state:
                del st.session_state.resilient_client
            st.success("å®¢æˆ·ç«¯çŠ¶æ€å·²é‡ç½®")
            st.rerun()
    
    with col_fix4:
        if st.button("ğŸ“ è·å–å¸®åŠ©", use_container_width=True):
            st.session_state.show_help = True
            st.rerun()
    
    # é”™è¯¯è¶‹åŠ¿åˆ†æ
    if 'resilient_client' in st.session_state:
        client = st.session_state.resilient_client
        error_types = client.session_stats.get('error_types', {})
        
        if error_types:
            st.subheader("ğŸ“ˆ é”™è¯¯è¶‹åŠ¿åˆ†æ")
            
            # æ˜¾ç¤ºé”™è¯¯ç±»å‹åˆ†å¸ƒ
            for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
                st.write(f"**{error_type}:** {count} æ¬¡")
            
            # æœ€è¿‘é”™è¯¯å†å²
            recent_errors = client.session_stats.get('last_errors', [])
            if recent_errors:
                with st.expander("ğŸ“ æœ€è¿‘é”™è¯¯å†å²"):
                    for error in recent_errors[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ªé”™è¯¯
                        st.write(f"**{error.get('timestamp', 'Unknown time')}** - {error.get('type', 'Unknown')} (å°è¯• {error.get('attempt', 'N/A')})")
                        st.caption(error.get('message', 'No message')[:100])

def show_help_panel():
    """æ˜¾ç¤ºå¸®åŠ©é¢æ¿"""
    st.subheader("ğŸ“ é”™è¯¯è§£å†³å¸®åŠ©")
    
    st.markdown("""
    ### ğŸ”§ å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ
    
    #### 1. "Unexpected error in retry loop"
    - **åŸå› **: é‡è¯•æœºåˆ¶æœ¬èº«å‡ºç°é—®é¢˜
    - **è§£å†³**: ä½¿ç”¨"é‡ç½®å®¢æˆ·ç«¯"æŒ‰é’®ï¼Œç„¶åé‡æ–°é…ç½®API
    
    #### 2. 500 æœåŠ¡å™¨é”™è¯¯
    - **åŸå› **: APIæä¾›å•†æœåŠ¡å™¨ä¸´æ—¶æ•…éšœ
    - **è§£å†³**: ç­‰å¾…è‡ªåŠ¨é‡è¯•ï¼Œæˆ–åˆ‡æ¢åˆ°æ›´ç¨³å®šçš„æ¨¡å‹
    
    #### 3. 401/403 è®¤è¯é”™è¯¯
    - **åŸå› **: APIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³
    - **è§£å†³**: æ£€æŸ¥APIå¯†é’¥ï¼Œç¡®è®¤è´¦æˆ·ä½™é¢
    
    #### 4. æ¨¡å‹ä¸å¯ç”¨ (404)
    - **åŸå› **: é€‰æ‹©çš„æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨
    - **è§£å†³**: åˆ‡æ¢åˆ° flux.1-schnell (æœ€ç¨³å®š)
    
    #### 5. å‚æ•°éªŒè¯å¤±è´¥
    - **åŸå› **: è¾“å…¥å‚æ•°è¶…å‡ºå…è®¸èŒƒå›´
    - **è§£å†³**: ä½¿ç”¨"å®‰å…¨æ¨¡å¼"æˆ–ç®€åŒ–è®¾ç½®
    """)
    
    st.markdown("""
    ### ğŸ›¡ï¸ é¢„é˜²æªæ–½
    
    - **ä½¿ç”¨ç¨³å®šæ¨¡å‹**: ä¼˜å…ˆé€‰æ‹© flux.1-schnell
    - **åˆç†æç¤ºè¯**: ä¿æŒåœ¨1000å­—ç¬¦ä»¥å†…
    - **æ ‡å‡†å°ºå¯¸**: ä½¿ç”¨ 1024x1024 æœ€ç¨³å®š
    - **å°‘é‡ç”Ÿæˆ**: ä¸€æ¬¡ç”Ÿæˆ1-2å¼ å›¾ç‰‡
    - **å®šæœŸæµ‹è¯•**: å®šæœŸæµ‹è¯•APIè¿æ¥çŠ¶æ€
    """)
    
    if st.button("âœ… äº†è§£äº†", type="primary"):
        if 'show_help' in st.session_state:
            del st.session_state.show_help
        st.rerun()

# å…¶ä»–å‡½æ•°ä¿æŒä¸å˜...
def create_resilient_client() -> Optional[ResilientFluxClient]:
    """åˆ›å»ºå¼¹æ€§å®¢æˆ·ç«¯"""
    try:
        if 'api_config' not in st.session_state or not st.session_state.api_config.get('api_key'):
            return None
        
        config = st.session_state.api_config
        return ResilientFluxClient(
            api_key=config['api_key'],
            base_url=config['base_url']
        )
    except Exception as e:
        st.error(f"åˆ›å»ºå¼¹æ€§å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
        return None

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []

# API å’Œæ¨¡å‹é…ç½®
API_PROVIDERS = {
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1",
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI å›¾åƒç”ŸæˆæœåŠ¡",
        "icon": "âš“"
    }
}

FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€ç¨³å®šçš„æ¨¡å‹ï¼Œæ¨èç”¨äºé”™è¯¯æ¢å¤",
        "icon": "âš¡",
        "reliability": "é«˜"
    },
    "flux.1-krea-dev": {
        "name": "FLUX.1 Krea Dev", 
        "description": "åˆ›æ„å¼€å‘ç‰ˆæœ¬",
        "icon": "ğŸ¨",
        "reliability": "ä¸­"
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ——èˆ°æ¨¡å‹",
        "icon": "ğŸ‘‘",
        "reliability": "ä¸­"
    }
}

def show_api_settings():
    """æ˜¾ç¤ºAPIè®¾ç½®"""
    st.subheader("ğŸ”‘ API è®¾ç½®")
    
    current_key = st.session_state.api_config.get('api_key', '')
    
    api_key_input = st.text_input(
        "API å¯†é’¥",
        value="",
        type="password",
        placeholder="è¯·è¾“å…¥ API å¯†é’¥...",
    )
    
    base_url_input = st.text_input(
        "API ç«¯ç‚¹",
        value=st.session_state.api_config.get('base_url', 'https://api.navy/v1'),
    )
    
    if st.button("ğŸ’¾ ä¿å­˜è®¾ç½®", type="primary"):
        if api_key_input or current_key:
            st.session_state.api_config = {
                'provider': 'Navy',
                'api_key': api_key_input or current_key,
                'base_url': base_url_input,
                'validated': False
            }
            st.success("âœ… è®¾ç½®å·²ä¿å­˜")
            st.rerun()

# åˆå§‹åŒ–
init_session_state()
resilient_client = create_resilient_client()
api_configured = resilient_client is not None

# ä¸»ç•Œé¢
st.title("ğŸ¨ Flux AI å›¾åƒç”Ÿæˆå™¨ Pro - è¯¦ç»†é”™è¯¯ä¿®å¤ç‰ˆ")

# å¸®åŠ©é¢æ¿æ£€æŸ¥
if st.session_state.get('show_help', False):
    show_help_panel()
else:
    # ä¾§è¾¹æ 
    with st.sidebar:
        show_api_settings()
        
        if api_configured:
            st.success("ğŸŸ¢ API å·²é…ç½®")
            
            # æ˜¾ç¤ºå®¢æˆ·ç«¯ç»Ÿè®¡
            stats = resilient_client.session_stats
            if stats['total_requests'] > 0:
                success_rate = stats['successful_requests'] / stats['total_requests'] * 100
                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
                
                if stats['error_types']:
                    st.subheader("âš ï¸ é”™è¯¯ç»Ÿè®¡")
                    for error_type, count in list(stats['error_types'].items())[:3]:
                        st.write(f"â€¢ {error_type}: {count}æ¬¡")
        else:
            st.error("ğŸ”´ API æœªé…ç½®")
    
    # ä¸»ç”Ÿæˆç•Œé¢
    if not api_configured:
        st.error("âš ï¸ è¯·å…ˆé…ç½® API å¯†é’¥")
    else:
        st.session_state.resilient_client = resilient_client
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ¯ å›¾åƒç”Ÿæˆ")
            
            # å®‰å…¨æ¨¡å¼æ£€æŸ¥
            if 'safe_mode_params' in st.session_state:
                safe_params = st.session_state.safe_mode_params
                st.success("ğŸ›¡ï¸ å®‰å…¨æ¨¡å¼å·²å¯ç”¨")
                
                selected_model = safe_params.get('model', 'flux.1-schnell')
                selected_size = safe_params.get('size', '1024x1024')
                num_images = safe_params.get('n', 1)
                
                del st.session_state.safe_mode_params
            else:
                # æ­£å¸¸é€‰æ‹©
                selected_model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹",
                    options=list(FLUX_MODELS.keys()),
                    format_func=lambda x: f"{FLUX_MODELS[x]['icon']} {FLUX_MODELS[x]['name']} (å¯é æ€§: {FLUX_MODELS[x]['reliability']})",
                    index=0
                )
                
                selected_size = st.selectbox(
                    "å›¾åƒå°ºå¯¸",
                    options=['1024x1024', '1152x896', '896x1152'],
                    index=0
                )
                
                num_images = st.slider("ç”Ÿæˆæ•°é‡", 1, 3, 1)
            
            prompt = st.text_area(
                "è¾“å…¥æç¤ºè¯",
                height=100,
                placeholder="ä¾‹å¦‚: A simple cat sitting on a table"
            )
            
            generate_btn = st.button(
                "ğŸš€ ç”Ÿæˆå›¾åƒ",
                type="primary",
                disabled=not prompt.strip()
            )
            
            # é‡è¯•æ£€æŸ¥
            if st.session_state.get('retry_generation', False):
                generate_btn = True
                del st.session_state.retry_generation
        
        with col2:
            st.subheader("ğŸ›¡ï¸ ç³»ç»ŸçŠ¶æ€")
            st.success("âœ… å¢å¼ºé”™è¯¯å¤„ç†å·²å¯ç”¨")
            st.info("ğŸ”§ è¯¦ç»†é”™è¯¯è¯Šæ–­")
            st.info("ğŸ”„ æ™ºèƒ½é‡è¯•æœºåˆ¶")
            st.info("ğŸ¯ è‡ªåŠ¨å‚æ•°ä¼˜åŒ–")
            
            if resilient_client.session_stats['total_requests'] > 0:
                st.subheader("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
                stats = resilient_client.session_stats
                st.write(f"æ€»è¯·æ±‚: {stats['total_requests']}")
                st.write(f"æˆåŠŸ: {stats['successful_requests']}")
                st.write(f"å¤±è´¥: {stats['failed_requests']}")
                st.write(f"é‡è¯•: {stats['retry_attempts']}")
        
        # ç”Ÿæˆé€»è¾‘
        if generate_btn and prompt.strip():
            st.subheader("ğŸ”„ ç”Ÿæˆè¿›åº¦")
            
            generation_params = {
                "model": selected_model,
                "prompt": prompt,
                "n": num_images,
                "size": selected_size
            }
            
            success, result, diagnostic_info = resilient_client.generate_with_resilience(**generation_params)
            
            if success:
                response = result
                st.success(f"âœ¨ ç”ŸæˆæˆåŠŸ! {diagnostic_info.get('message', '')}")
                
                for i, image_data in enumerate(response.data):
                    st.subheader(f"å›¾åƒ {i+1}")
                    
                    try:
                        img_response = requests.get(image_data.url)
                        img = Image.open(BytesIO(img_response.content))
                        st.image(img, use_container_width=True)
                        
                        # ä¸‹è½½æŒ‰é’®
                        img_buffer = BytesIO()
                        img.save(img_buffer, format='PNG')
                        st.download_button(
                            label=f"ğŸ“¥ ä¸‹è½½å›¾åƒ {i+1}",
                            data=img_buffer.getvalue(),
                            file_name=f"flux_generated_{i+1}.png",
                            mime="image/png"
                        )
                    except Exception as img_error:
                        st.error(f"æ˜¾ç¤ºå›¾åƒå¤±è´¥: {str(img_error)}")
            else:
                error_analysis = result
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {error_analysis.get('type', 'unknown')}")
                show_error_recovery_panel(error_analysis, diagnostic_info)

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ›¡ï¸ **Flux AI å›¾åƒç”Ÿæˆå™¨ Pro - è¯¦ç»†é”™è¯¯ä¿®å¤ç‰ˆ** | ğŸ”§ å®Œæ•´é”™è¯¯è¯Šæ–­ | ğŸ”„ æ™ºèƒ½é‡è¯• | ğŸ’¡ è¯¦ç»†è§£å†³æ–¹æ¡ˆ")
