import streamlit as st
from openai import OpenAI
from PIL import Image
import requests
from io import BytesIO
import datetime
import base64
from typing import Dict, List, Optional, Tuple
import time
import random
import asyncio
import threading
import json

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Flux AI åœ–åƒç”Ÿæˆå™¨ Pro", 
    page_icon="ğŸ¨", 
    layout="wide"
)

# API æä¾›å•†é…ç½®
API_PROVIDERS = {
    "OpenAI Compatible": {
        "name": "OpenAI Compatible API",
        "base_url_default": "https://api.openai.com/v1",
        "key_prefix": "sk-",
        "description": "OpenAI å®˜æ–¹æˆ–å…¼å®¹çš„ API æœå‹™",
        "icon": "ğŸ¤–"
    },
    "Navy": {
        "name": "Navy API",
        "base_url_default": "https://api.navy/v1",
        "key_prefix": "sk-",
        "description": "Navy æä¾›çš„ AI åœ–åƒç”Ÿæˆæœå‹™",
        "icon": "âš“"
    },
    "Custom": {
        "name": "è‡ªå®šç¾© API",
        "base_url_default": "",
        "key_prefix": "",
        "description": "è‡ªå®šç¾©çš„ API ç«¯é»",
        "icon": "ğŸ”§"
    }
}

# Flux æ¨¡å‹é…ç½®ï¼ˆå¢å¼·ç‰ˆï¼‰
FLUX_MODELS = {
    "flux.1-schnell": {
        "name": "FLUX.1 Schnell",
        "description": "æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ï¼Œé–‹æºæ¨¡å‹",
        "icon": "âš¡",
        "type": "å¿«é€Ÿç”Ÿæˆ",
        "test_prompt": "A simple cat sitting on a table",
        "expected_size": "1024x1024",
        "priority": 1  # å„ªå…ˆç´šï¼Œ1æœ€é«˜
    },
    "flux.1-krea-dev": {
        "name": "FLUX.1 Krea Dev", 
        "description": "å‰µæ„é–‹ç™¼ç‰ˆæœ¬ï¼Œé©åˆå¯¦é©—æ€§ç”Ÿæˆ",
        "icon": "ğŸ¨",
        "type": "å‰µæ„é–‹ç™¼",
        "test_prompt": "Creative digital art of a futuristic city",
        "expected_size": "1024x1024",
        "priority": 2
    },
    "flux.1.1-pro": {
        "name": "FLUX.1.1 Pro",
        "description": "æ”¹é€²çš„æ——è‰¦æ¨¡å‹ï¼Œæœ€ä½³å“è³ª",
        "icon": "ğŸ‘‘",
        "type": "æ——è‰¦ç‰ˆæœ¬",
        "test_prompt": "Professional portrait of a person in business attire",
        "expected_size": "1024x1024",
        "priority": 3
    },
    "flux.1-kontext-pro": {
        "name": "FLUX.1 Kontext Pro",
        "description": "æ”¯æŒåœ–åƒç·¨è¼¯å’Œä¸Šä¸‹æ–‡ç†è§£",
        "icon": "ğŸ”§",
        "type": "ç·¨è¼¯å°ˆç”¨",
        "test_prompt": "Abstract geometric shapes in vibrant colors",
        "expected_size": "1024x1024",
        "priority": 4
    },
    "flux.1-kontext-max": {
        "name": "FLUX.1 Kontext Max",
        "description": "æœ€é«˜æ€§èƒ½ç‰ˆæœ¬ï¼Œæ¥µè‡´å“è³ª",
        "icon": "ğŸš€",
        "type": "æ¥µè‡´æ€§èƒ½",
        "test_prompt": "Ultra-detailed landscape with mountains and lake",
        "expected_size": "1024x1024",
        "priority": 5
    }
}

def validate_api_key(api_key: str, base_url: str) -> Tuple[bool, str]:
    """é©—è­‰ API å¯†é‘°æ˜¯å¦æœ‰æ•ˆ"""
    try:
        test_client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        response = test_client.models.list()
        return True, "API å¯†é‘°é©—è­‰æˆåŠŸ"
        
    except Exception as e:
        error_msg = str(e)
        if "401" in error_msg or "Unauthorized" in error_msg:
            return False, "API å¯†é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
        elif "403" in error_msg or "Forbidden" in error_msg:
            return False, "API å¯†é‘°æ²’æœ‰è¶³å¤ æ¬Šé™"
        elif "404" in error_msg:
            return False, "API ç«¯é»ä¸å­˜åœ¨æˆ–ä¸æ­£ç¢º"
        elif "timeout" in error_msg.lower():
            return False, "API é€£æ¥è¶…æ™‚"
        else:
            return False, f"API é©—è­‰å¤±æ•—: {error_msg[:100]}"

def get_available_models(client: OpenAI) -> Tuple[bool, List[str]]:
    """ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = client.models.list()
        model_ids = [model.id for model in response.data]
        return True, model_ids
    except Exception as e:
        return False, [str(e)]

def test_model_availability(client: OpenAI, model_name: str, test_prompt: str = None) -> Dict:
    """æ¸¬è©¦ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§"""
    if test_prompt is None:
        test_prompt = FLUX_MODELS.get(model_name, {}).get('test_prompt', 'A simple test image')
    
    test_result = {
        'model': model_name,
        'available': False,
        'response_time': 0,
        'error': None,
        'details': {}
    }
    
    try:
        start_time = time.time()
        
        # å˜—è©¦ç”Ÿæˆä¸€å¼µæ¸¬è©¦åœ–åƒ
        response = client.images.generate(
            model=model_name,
            prompt=test_prompt,
            n=1,
            size="1024x1024"
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        test_result.update({
            'available': True,
            'response_time': response_time,
            'details': {
                'image_count': len(response.data),
                'test_prompt': test_prompt,
                'image_url': response.data[0].url if response.data else None
            }
        })
        
    except Exception as e:
        error_msg = str(e)
        test_result.update({
            'available': False,
            'error': error_msg,
            'details': {
                'error_type': 'generation_failed',
                'test_prompt': test_prompt
            }
        })
    
    return test_result

def batch_test_models(client: OpenAI, models_to_test: List[str] = None) -> Dict[str, Dict]:
    """æ‰¹é‡æ¸¬è©¦å¤šå€‹æ¨¡å‹çš„å¯ç”¨æ€§"""
    if models_to_test is None:
        models_to_test = list(FLUX_MODELS.keys())
    
    results = {}
    
    for model_name in models_to_test:
        st.write(f"ğŸ§ª æ­£åœ¨æ¸¬è©¦ {FLUX_MODELS.get(model_name, {}).get('name', model_name)}...")
        
        result = test_model_availability(client, model_name)
        results[model_name] = result
        
        # å¯¦æ™‚é¡¯ç¤ºçµæœ
        if result['available']:
            st.success(f"âœ… {model_name} å¯ç”¨ (éŸ¿æ‡‰æ™‚é–“: {result['response_time']:.2f}s)")
        else:
            st.error(f"âŒ {model_name} ä¸å¯ç”¨: {result['error'][:100]}...")
        
        # é¿å…è«‹æ±‚éæ–¼é »ç¹
        time.sleep(1)
    
    return results

def show_model_status_dashboard():
    """é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹å„€è¡¨æ¿"""
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    st.subheader("ğŸ¯ æ¨¡å‹å¯ç”¨æ€§ç‹€æ…‹")
    
    # æ§åˆ¶æŒ‰éˆ•
    col_btn1, col_btn2, col_btn3 = st.columns(3)
    
    with col_btn1:
        test_all_btn = st.button("ğŸ§ª æ¸¬è©¦æ‰€æœ‰æ¨¡å‹", type="primary")
    
    with col_btn2:
        refresh_btn = st.button("ğŸ”„ åˆ·æ–°ç‹€æ…‹")
    
    with col_btn3:
        clear_cache_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤ç·©å­˜")
    
    # åŸ·è¡Œæ‰¹é‡æ¸¬è©¦
    if test_all_btn:
        if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
            client = OpenAI(
                api_key=st.session_state.api_config['api_key'],
                base_url=st.session_state.api_config['base_url']
            )
            
            with st.spinner("æ­£åœ¨æ‰¹é‡æ¸¬è©¦æ‰€æœ‰æ¨¡å‹..."):
                st.session_state.model_test_results = batch_test_models(client)
                st.session_state.last_test_time = datetime.datetime.now()
            
            st.success("âœ… æ‰¹é‡æ¸¬è©¦å®Œæˆï¼")
            st.rerun()
        else:
            st.error("âŒ è«‹å…ˆé…ç½® API å¯†é‘°")
    
    # åˆ·æ–°ç‹€æ…‹
    if refresh_btn:
        st.rerun()
    
    # æ¸…é™¤ç·©å­˜
    if clear_cache_btn:
        st.session_state.model_test_results = {}
        if 'last_test_time' in st.session_state:
            del st.session_state.last_test_time
        st.success("ç·©å­˜å·²æ¸…é™¤")
        st.rerun()
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœ
    if st.session_state.model_test_results:
        # é¡¯ç¤ºæœ€å¾Œæ¸¬è©¦æ™‚é–“
        if 'last_test_time' in st.session_state:
            st.caption(f"æœ€å¾Œæ¸¬è©¦æ™‚é–“: {st.session_state.last_test_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # çµ±è¨ˆæ¦‚è¦½
        total_models = len(st.session_state.model_test_results)
        available_models = sum(1 for result in st.session_state.model_test_results.values() 
                              if result.get('available', False))
        
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        
        with col_stat1:
            st.metric("ç¸½æ¨¡å‹æ•¸", total_models)
        
        with col_stat2:
            st.metric("å¯ç”¨æ¨¡å‹", available_models)
        
        with col_stat3:
            availability_rate = (available_models / total_models * 100) if total_models > 0 else 0
            st.metric("å¯ç”¨ç‡", f"{availability_rate:.1f}%")
        
        # è©³ç´°çµæœè¡¨æ ¼
        st.subheader("ğŸ“Š è©³ç´°æ¸¬è©¦çµæœ")
        
        # æŒ‰å¯ç”¨æ€§å’Œå„ªå…ˆç´šæ’åº
        sorted_results = sorted(
            st.session_state.model_test_results.items(),
            key=lambda x: (
                not x[1].get('available', False),  # å¯ç”¨çš„åœ¨å‰
                FLUX_MODELS.get(x[0], {}).get('priority', 999)  # å„ªå…ˆç´šé«˜çš„åœ¨å‰
            )
        )
        
        for model_name, result in sorted_results:
            model_info = FLUX_MODELS.get(model_name, {})
            
            # å‰µå»ºå±•é–‹æ¡†
            status_icon = "âœ…" if result.get('available', False) else "âŒ"
            response_time = result.get('response_time', 0)
            time_display = f" ({response_time:.2f}s)" if response_time > 0 else ""
            
            with st.expander(
                f"{status_icon} {model_info.get('icon', 'ğŸ”§')} {model_info.get('name', model_name)}{time_display}"
            ):
                col_info, col_test = st.columns([2, 1])
                
                with col_info:
                    st.markdown(f"**æ¨¡å‹ID**: `{model_name}`")
                    st.markdown(f"**æè¿°**: {model_info.get('description', 'N/A')}")
                    st.markdown(f"**é¡å‹**: {model_info.get('type', 'N/A')}")
                    
                    if result.get('available', False):
                        st.success("âœ… æ¨¡å‹å¯ç”¨")
                        st.markdown(f"**éŸ¿æ‡‰æ™‚é–“**: {response_time:.2f} ç§’")
                        
                        # é¡¯ç¤ºæ¸¬è©¦åœ–åƒï¼ˆå¦‚æœæœ‰ï¼‰
                        test_image_url = result.get('details', {}).get('image_url')
                        if test_image_url:
                            st.markdown("**æ¸¬è©¦åœ–åƒé è¦½**:")
                            try:
                                st.image(test_image_url, width=200, caption="æ¸¬è©¦ç”Ÿæˆçš„åœ–åƒ")
                            except:
                                st.info("ç„¡æ³•è¼‰å…¥æ¸¬è©¦åœ–åƒé è¦½")
                    else:
                        st.error("âŒ æ¨¡å‹ä¸å¯ç”¨")
                        error_msg = result.get('error', 'Unknown error')
                        st.markdown(f"**éŒ¯èª¤ä¿¡æ¯**: {error_msg}")
                        
                        # æ ¹æ“šéŒ¯èª¤é¡å‹æä¾›å»ºè­°
                        if "401" in error_msg or "403" in error_msg:
                            st.warning("ğŸ’¡ å»ºè­°æª¢æŸ¥ API å¯†é‘°æ¬Šé™")
                        elif "404" in error_msg:
                            st.warning("ğŸ’¡ æ¨¡å‹å¯èƒ½ä¸å­˜åœ¨æˆ–æš«æ™‚ä¸å¯ç”¨")
                        elif "429" in error_msg:
                            st.warning("ğŸ’¡ è«‹æ±‚éæ–¼é »ç¹ï¼Œç¨å¾Œå†è©¦")
                        elif "500" in error_msg:
                            st.warning("ğŸ’¡ æœå‹™å™¨éŒ¯èª¤ï¼Œæ¨¡å‹å¯èƒ½æš«æ™‚é›¢ç·š")
                
                with col_test:
                    st.markdown("**å–®ç¨æ¸¬è©¦**")
                    
                    # è‡ªå®šç¾©æ¸¬è©¦æç¤ºè©
                    custom_prompt = st.text_input(
                        "è‡ªå®šç¾©æ¸¬è©¦æç¤ºè©",
                        value=model_info.get('test_prompt', 'A simple test image'),
                        key=f"test_prompt_{model_name}"
                    )
                    
                    if st.button(f"ğŸ”¬ æ¸¬è©¦æ­¤æ¨¡å‹", key=f"test_{model_name}"):
                        if 'api_config' in st.session_state and st.session_state.api_config.get('api_key'):
                            client = OpenAI(
                                api_key=st.session_state.api_config['api_key'],
                                base_url=st.session_state.api_config['base_url']
                            )
                            
                            with st.spinner(f"æ­£åœ¨æ¸¬è©¦ {model_name}..."):
                                test_result = test_model_availability(client, model_name, custom_prompt)
                                st.session_state.model_test_results[model_name] = test_result
                            
                            st.rerun()
                        else:
                            st.error("è«‹å…ˆé…ç½® API å¯†é‘°")
    
    else:
        st.info("ğŸ§ª é»æ“Š 'æ¸¬è©¦æ‰€æœ‰æ¨¡å‹' é–‹å§‹æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§")

def get_recommended_models() -> List[str]:
    """åŸºæ–¼æ¸¬è©¦çµæœæ¨è–¦æœ€ä½³æ¨¡å‹"""
    if 'model_test_results' not in st.session_state:
        return []
    
    # ç¯©é¸å¯ç”¨çš„æ¨¡å‹
    available_models = [
        model_name for model_name, result in st.session_state.model_test_results.items()
        if result.get('available', False)
    ]
    
    # æŒ‰å„ªå…ˆç´šå’ŒéŸ¿æ‡‰æ™‚é–“æ’åº
    recommended = sorted(
        available_models,
        key=lambda x: (
            FLUX_MODELS.get(x, {}).get('priority', 999),
            st.session_state.model_test_results[x].get('response_time', 999)
        )
    )
    
    return recommended[:3]  # è¿”å›å‰3å€‹æ¨è–¦æ¨¡å‹

def show_model_recommendations():
    """é¡¯ç¤ºæ¨¡å‹æ¨è–¦"""
    recommended = get_recommended_models()
    
    if recommended:
        st.subheader("â­ æ¨è–¦æ¨¡å‹")
        
        for i, model_name in enumerate(recommended):
            model_info = FLUX_MODELS.get(model_name, {})
            result = st.session_state.model_test_results.get(model_name, {})
            
            col_icon, col_info, col_metrics = st.columns([1, 3, 2])
            
            with col_icon:
                st.markdown(f"### {i+1}. {model_info.get('icon', 'ğŸ”§')}")
            
            with col_info:
                st.markdown(f"**{model_info.get('name', model_name)}**")
                st.caption(model_info.get('description', 'N/A'))
            
            with col_metrics:
                response_time = result.get('response_time', 0)
                st.metric("éŸ¿æ‡‰æ™‚é–“", f"{response_time:.2f}s")
        
        # è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹
        if st.button("ğŸš€ ä½¿ç”¨æ¨è–¦çš„æœ€ä½³æ¨¡å‹"):
            st.session_state.recommended_model = recommended[0]
            st.success(f"å·²é¸æ“‡: {FLUX_MODELS.get(recommended[0], {}).get('name', recommended[0])}")
            st.rerun()
    else:
        st.info("è«‹å…ˆæ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§ä»¥ç²å–æ¨è–¦")

def init_api_client():
    """åˆå§‹åŒ– API å®¢æˆ¶ç«¯"""
    if 'api_config' in st.session_state and st.session_state.api_config['api_key']:
        api_key = st.session_state.api_config['api_key']
        base_url = st.session_state.api_config['base_url']
    elif 'OPENAI_API_KEY' in st.secrets:
        api_key = st.secrets.get("OPENAI_API_KEY")
        base_url = st.secrets.get("OPENAI_BASE_URL", "https://api.navy/v1")
    else:
        return None
    
    try:
        return OpenAI(
            api_key=api_key,
            base_url=base_url
        )
    except Exception:
        return None

def show_api_settings():
    """é¡¯ç¤º API è¨­ç½®ç•Œé¢"""
    st.subheader("ğŸ”‘ API è¨­ç½®")
    
    provider_options = list(API_PROVIDERS.keys())
    current_provider = st.session_state.api_config.get('provider', 'Navy')
    
    selected_provider = st.selectbox(
        "é¸æ“‡ API æä¾›å•†",
        options=provider_options,
        index=provider_options.index(current_provider) if current_provider in provider_options else 1,
        format_func=lambda x: f"{API_PROVIDERS[x]['icon']} {API_PROVIDERS[x]['name']}"
    )
    
    provider_info = API_PROVIDERS[selected_provider]
    st.info(f"ğŸ“‹ {provider_info['description']}")
    
    current_key = st.session_state.api_config.get('api_key', '')
    masked_key = '*' * 20 + current_key[-8:] if len(current_key) > 8 else ''
    
    api_key_input = st.text_input(
        "API å¯†é‘°",
        value="",
        type="password",
        placeholder=f"è«‹è¼¸å…¥ {provider_info['name']} çš„ API å¯†é‘°...",
        help=f"API å¯†é‘°é€šå¸¸ä»¥ '{provider_info['key_prefix']}' é–‹é ­"
    )
    
    if current_key and not api_key_input:
        st.caption(f"ğŸ” ç•¶å‰å¯†é‘°: {masked_key}")
    
    base_url_input = st.text_input(
        "API ç«¯é» URL",
        value=st.session_state.api_config.get('base_url', provider_info['base_url_default']),
        placeholder=provider_info['base_url_default'],
        help="API æœå‹™çš„åŸºç¤ URL"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        save_btn = st.button("ğŸ’¾ ä¿å­˜è¨­ç½®", type="primary")
    
    with col2:
        test_btn = st.button("ğŸ§ª æ¸¬è©¦é€£æ¥")
    
    with col3:
        clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤è¨­ç½®", type="secondary")
    
    if save_btn:
        if not api_key_input and not current_key:
            st.error("âŒ è«‹è¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            final_api_key = api_key_input if api_key_input else current_key
            
            st.session_state.api_config = {
                'provider': selected_provider,
                'api_key': final_api_key,
                'base_url': base_url_input,
                'validated': False
            }
            st.success("âœ… API è¨­ç½®å·²ä¿å­˜")
            
            # æ¸…é™¤èˆŠçš„æ¨¡å‹æ¸¬è©¦çµæœ
            st.session_state.model_test_results = {}
            st.rerun()
    
    if test_btn:
        test_api_key = api_key_input if api_key_input else current_key
        if not test_api_key:
            st.error("âŒ è«‹å…ˆè¼¸å…¥ API å¯†é‘°")
        elif not base_url_input:
            st.error("âŒ è«‹è¼¸å…¥ API ç«¯é» URL")
        else:
            with st.spinner("æ­£åœ¨æ¸¬è©¦ API é€£æ¥..."):
                is_valid, message = validate_api_key(test_api_key, base_url_input)
                if is_valid:
                    st.success(f"âœ… {message}")
                    st.session_state.api_config['validated'] = True
                    
                    # åŒæ™‚ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
                    try:
                        client = OpenAI(api_key=test_api_key, base_url=base_url_input)
                        success, models = get_available_models(client)
                        if success:
                            st.info(f"ğŸ¯ ç™¼ç¾ {len(models)} å€‹å¯ç”¨æ¨¡å‹")
                            
                            # æª¢æŸ¥ Flux æ¨¡å‹
                            flux_models = [m for m in models if 'flux' in m.lower()]
                            if flux_models:
                                st.success(f"ğŸ¨ ç™¼ç¾ {len(flux_models)} å€‹ Flux æ¨¡å‹")
                            else:
                                st.warning("âš ï¸ æœªç™¼ç¾ Flux æ¨¡å‹ï¼Œè«‹æª¢æŸ¥ API æä¾›å•†")
                        else:
                            st.warning("âš ï¸ ç„¡æ³•ç²å–æ¨¡å‹åˆ—è¡¨ï¼Œä½†åŸºæœ¬é€£æ¥æ­£å¸¸")
                    except Exception as e:
                        st.warning(f"âš ï¸ API é€£æ¥æˆåŠŸï¼Œä½†ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {str(e)[:100]}")
                        
                else:
                    st.error(f"âŒ {message}")
                    st.session_state.api_config['validated'] = False
    
    if clear_btn:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
        st.session_state.model_test_results = {}
        st.success("ğŸ—‘ï¸ API è¨­ç½®å·²æ¸…é™¤")
        st.rerun()
    
    if st.session_state.api_config['api_key']:
        status_col1, status_col2 = st.columns(2)
        
        with status_col1:
            if st.session_state.api_config['validated']:
                st.success("ğŸŸ¢ API å·²é©—è­‰")
            else:
                st.warning("ğŸŸ¡ API æœªé©—è­‰")
        
        with status_col2:
            st.info(f"ğŸ”§ ä½¿ç”¨: {provider_info['name']}")

def generate_images_with_retry(client, **params) -> Tuple[bool, any]:
    """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åœ–åƒç”Ÿæˆ"""
    max_retries = 3
    base_delay = 2
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                st.info(f"ğŸ”„ å˜—è©¦é‡æ–°ç”Ÿæˆ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")
            
            response = client.images.generate(**params)
            return True, response
            
        except Exception as e:
            error_msg = str(e)
            
            if attempt < max_retries - 1:
                should_retry = False
                if "500" in error_msg or "502" in error_msg or "503" in error_msg:
                    should_retry = True
                elif "429" in error_msg:
                    should_retry = True
                elif "timeout" in error_msg.lower():
                    should_retry = True
                
                if should_retry:
                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                    st.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—ï¼Œ{delay:.1f} ç§’å¾Œé‡è©¦...")
                    time.sleep(delay)
                    continue
                else:
                    return False, error_msg
            else:
                return False, error_msg
    
    return False, "æ‰€æœ‰é‡è©¦å‡å¤±æ•—"

# åˆå§‹åŒ– session state
def init_session_state():
    """åˆå§‹åŒ–æœƒè©±ç‹€æ…‹"""
    if 'api_config' not in st.session_state:
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
    
    if 'generation_history' not in st.session_state:
        st.session_state.generation_history = []
    
    if 'favorite_images' not in st.session_state:
        st.session_state.favorite_images = []
    
    if 'model_test_results' not in st.session_state:
        st.session_state.model_test_results = {}
    
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "ç”Ÿæˆå™¨"

def add_to_history(prompt: str, model: str, images: List[str], metadata: Dict):
    """æ·»åŠ ç”Ÿæˆè¨˜éŒ„åˆ°æ­·å²"""
    history_item = {
        "timestamp": datetime.datetime.now(),
        "prompt": prompt,
        "model": model,
        "images": images,
        "metadata": metadata,
        "id": len(st.session_state.generation_history)
    }
    
    st.session_state.generation_history.insert(0, history_item)
    
    if len(st.session_state.generation_history) > 50:
        st.session_state.generation_history = st.session_state.generation_history[:50]

def display_image_with_actions(image_url: str, image_id: str, history_item: Dict = None):
    """é¡¯ç¤ºåœ–åƒå’Œç›¸é—œæ“ä½œ"""
    col1, col2, col3 = st.columns([1, 1, 1])
    
    img_response = requests.get(image_url)
    img = Image.open(BytesIO(img_response.content))
    
    st.image(img, use_container_width=True)
    
    with col1:
        img_buffer = BytesIO()
        img.save(img_buffer, format='PNG')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰",
            data=img_buffer.getvalue(),
            file_name=f"flux_generated_{image_id}.png",
            mime="image/png",
            key=f"download_{image_id}",
            use_container_width=True
        )
    
    with col2:
        is_favorite = any(fav['id'] == image_id for fav in st.session_state.favorite_images)
        if st.button(
            "â­ å·²æ”¶è—" if is_favorite else "â˜† æ”¶è—",
            key=f"favorite_{image_id}",
            use_container_width=True
        ):
            if is_favorite:
                st.session_state.favorite_images = [
                    fav for fav in st.session_state.favorite_images if fav['id'] != image_id
                ]
                st.success("å·²å–æ¶ˆæ”¶è—")
            else:
                favorite_item = {
                    "id": image_id,
                    "image_url": image_url,
                    "timestamp": datetime.datetime.now(),
                    "history_item": history_item
                }
                st.session_state.favorite_images.append(favorite_item)
                st.success("å·²åŠ å…¥æ”¶è—")
    
    with col3:
        if history_item and st.button(
            "ğŸ”„ é‡æ–°ç”Ÿæˆ",
            key=f"regenerate_{image_id}",
            use_container_width=True
        ):
            st.session_state.regenerate_prompt = history_item['prompt']
            st.session_state.regenerate_model = history_item['model']
            st.session_state.current_page = "ç”Ÿæˆå™¨"
            st.rerun()

# åˆå§‹åŒ–æœƒè©±ç‹€æ…‹
init_session_state()

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = init_api_client()
api_configured = client is not None

# å´é‚Šæ¬„ API è¨­ç½®å’Œæ¨¡å‹ç‹€æ…‹
with st.sidebar:
    show_api_settings()
    
    st.markdown("---")
    if api_configured:
        st.success("ğŸŸ¢ API å·²é…ç½®")
        provider = st.session_state.api_config.get('provider', 'Unknown')
        st.caption(f"ä½¿ç”¨: {API_PROVIDERS.get(provider, {}).get('name', provider)}")
    else:
        st.error("ğŸ”´ API æœªé…ç½®")
    
    # æ¨¡å‹ç‹€æ…‹æ¦‚è¦½
    st.markdown("### ğŸ¯ æ¨¡å‹ç‹€æ…‹")
    if st.session_state.model_test_results:
        available_count = sum(1 for result in st.session_state.model_test_results.values() 
                             if result.get('available', False))
        total_count = len(st.session_state.model_test_results)
        
        st.metric("å¯ç”¨æ¨¡å‹", f"{available_count}/{total_count}")
        
        # é¡¯ç¤ºæ¨è–¦æ¨¡å‹
        recommended = get_recommended_models()
        if recommended:
            st.markdown("**æ¨è–¦æ¨¡å‹:**")
            for model in recommended[:2]:  # é¡¯ç¤ºå‰2å€‹
                model_name = FLUX_MODELS.get(model, {}).get('name', model)
                st.write(f"â€¢ {model_name}")
    else:
        st.info("æœªé€²è¡Œæ¨¡å‹æ¸¬è©¦")
    
    # ä½¿ç”¨çµ±è¨ˆ
    st.markdown("### ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
    total_generations = len(st.session_state.generation_history)
    total_favorites = len(st.session_state.favorite_images)
    
    st.metric("ç¸½ç”Ÿæˆæ•¸", total_generations)
    st.metric("æ”¶è—æ•¸é‡", total_favorites)
    
    # å¿«é€Ÿæ“ä½œ
    st.markdown("---")
    st.markdown("### âš¡ å¿«é€Ÿæ“ä½œ")
    
    if st.button("ğŸ§ª å¿«é€Ÿæ¸¬è©¦æ‰€æœ‰æ¨¡å‹", use_container_width=True):
        if api_configured:
            st.session_state.show_model_test = True
            st.rerun()
        else:
            st.warning("è«‹å…ˆé…ç½® API å¯†é‘°")
    
    if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰è¨­ç½®", use_container_width=True):
        st.session_state.api_config = {
            'provider': 'Navy',
            'api_key': '',
            'base_url': 'https://api.navy/v1',
            'validated': False
        }
        st.session_state.model_test_results = {}
        st.success("è¨­ç½®å·²é‡ç½®")
        st.rerun()

# ä¸»æ¨™é¡Œ
st.title("ğŸ¨ Flux AI åœ–åƒç”Ÿæˆå™¨ Pro")

# API ç‹€æ…‹è­¦å‘Š
if not api_configured:
    st.error("âš ï¸ è«‹å…ˆé…ç½® API å¯†é‘°æ‰èƒ½ä½¿ç”¨åœ–åƒç”ŸæˆåŠŸèƒ½")
    st.info("ğŸ‘ˆ é»æ“Šå´é‚Šæ¬„çš„ 'API è¨­ç½®' ä¾†é…ç½®ä½ çš„å¯†é‘°")

# é é¢å°èˆªï¼ˆæ–°å¢æ¨¡å‹æ¸¬è©¦é é¢ï¼‰
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸš€ åœ–åƒç”Ÿæˆ", 
    "ğŸ§ª æ¨¡å‹æ¸¬è©¦", 
    "ğŸ“š æ­·å²è¨˜éŒ„", 
    "â­ æ”¶è—å¤¾", 
    "ğŸ“Š çµ±è¨ˆ",
    "ğŸ’¡ å¹«åŠ©"
])

# åœ–åƒç”Ÿæˆé é¢ï¼ˆå¢å¼·ç‰ˆï¼‰
with tab1:
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„é…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯é–‹å§‹ç”Ÿæˆåœ–åƒ")
    else:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # æ™ºèƒ½æ¨¡å‹é¸æ“‡
            st.subheader("ğŸ¯ æ™ºèƒ½æ¨¡å‹é¸æ“‡")
            
            # é¡¯ç¤ºæ¨è–¦æ¨¡å‹
            recommended = get_recommended_models()
            if recommended:
                st.success("ğŸŒŸ åŸºæ–¼å¯ç”¨æ€§æ¸¬è©¦çš„æ¨è–¦æ¨¡å‹:")
                rec_cols = st.columns(len(recommended))
                
                selected_model = None
                for i, model_name in enumerate(recommended):
                    with rec_cols[i]:
                        model_info = FLUX_MODELS.get(model_name, {})
                        result = st.session_state.model_test_results.get(model_name, {})
                        response_time = result.get('response_time', 0)
                        
                        if st.button(
                            f"{model_info.get('icon', 'ğŸ”§')}\n{model_info.get('name', model_name)}\nâš¡{response_time:.1f}s",
                            key=f"rec_model_{model_name}",
                            use_container_width=True,
                            help=f"{model_info.get('description', '')} (éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s)"
                        ):
                            selected_model = model_name
                
                # å¦‚æœé»æ“Šäº†æ¨è–¦æ¨¡å‹ï¼Œæ›´æ–°é¸æ“‡
                if selected_model:
                    st.session_state.selected_model = selected_model
            
            # å‚³çµ±æ¨¡å‹é¸æ“‡ï¼ˆå‚™ç”¨ï¼‰
            with st.expander("ğŸ”§ æ‰‹å‹•é¸æ“‡æ¨¡å‹"):
                model_cols = st.columns(len(FLUX_MODELS))
                
                for i, (model_key, model_info) in enumerate(FLUX_MODELS.items()):
                    with model_cols[i]:
                        # é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹
                        if model_key in st.session_state.model_test_results:
                            result = st.session_state.model_test_results[model_key]
                            if result.get('available', False):
                                status = f"âœ… {result.get('response_time', 0):.1f}s"
                            else:
                                status = "âŒ ä¸å¯ç”¨"
                        else:
                            status = "â“ æœªæ¸¬è©¦"
                        
                        if st.button(
                            f"{model_info['icon']} {model_info['name']}\n{model_info['type']}\n{status}",
                            key=f"manual_model_{model_key}",
                            use_container_width=True,
                            help=model_info['description']
                        ):
                            st.session_state.selected_model = model_key
            
            # æœ€çµ‚æ¨¡å‹é¸æ“‡
            if 'selected_model' not in st.session_state:
                if recommended:
                    st.session_state.selected_model = recommended[0]
                else:
                    st.session_state.selected_model = list(FLUX_MODELS.keys())[0]
            
            final_selected_model = st.session_state.selected_model
            
            # é¡¯ç¤ºé¸ä¸­æ¨¡å‹çš„è©³ç´°ä¿¡æ¯
            model_info = FLUX_MODELS[final_selected_model]
            
            # æ¨¡å‹ç‹€æ…‹æª¢æŸ¥
            if final_selected_model in st.session_state.model_test_results:
                result = st.session_state.model_test_results[final_selected_model]
                if result.get('available', False):
                    st.success(f"âœ… å·²é¸æ“‡: {model_info['icon']} {model_info['name']} (éŸ¿æ‡‰æ™‚é–“: {result.get('response_time', 0):.2f}s)")
                else:
                    st.error(f"âŒ é¸ä¸­æ¨¡å‹ä¸å¯ç”¨: {model_info['name']}")
                    st.warning("å»ºè­°å…ˆæ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹")
            else:
                st.info(f"ğŸ“ å·²é¸æ“‡: {model_info['icon']} {model_info['name']} - {model_info['description']}")
                st.warning("âš ï¸ æœªæ¸¬è©¦æ­¤æ¨¡å‹å¯ç”¨æ€§ï¼Œå»ºè­°å…ˆé€²è¡Œæ¸¬è©¦")
            
            # å¿«é€Ÿæ¸¬è©¦ç•¶å‰æ¨¡å‹æŒ‰éˆ•
            if st.button("ğŸ§ª æ¸¬è©¦ç•¶å‰æ¨¡å‹", use_container_width=True):
                with st.spinner(f"æ­£åœ¨æ¸¬è©¦ {model_info['name']}..."):
                    test_result = test_model_availability(client, final_selected_model)
                    st.session_state.model_test_results[final_selected_model] = test_result
                
                if test_result['available']:
                    st.success(f"âœ… {model_info['name']} æ¸¬è©¦é€šéï¼")
                else:
                    st.error(f"âŒ {model_info['name']} æ¸¬è©¦å¤±æ•—: {test_result['error']}")
                
                st.rerun()
            
            # æç¤ºè©è¼¸å…¥
            st.subheader("âœï¸ è¼¸å…¥æç¤ºè©")
            
            # é‡æ–°ç”Ÿæˆæª¢æŸ¥
            default_prompt = ""
            if hasattr(st.session_state, 'regenerate_prompt'):
                default_prompt = st.session_state.regenerate_prompt
                if hasattr(st.session_state, 'regenerate_model'):
                    st.session_state.selected_model = st.session_state.regenerate_model
                delattr(st.session_state, 'regenerate_prompt')
                if hasattr(st.session_state, 'regenerate_model'):
                    delattr(st.session_state, 'regenerate_model')
            
            prompt = st.text_area(
                "æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„åœ–åƒ",
                value=default_prompt,
                height=120,
                placeholder="ä¾‹å¦‚ï¼šA cute cat wearing a wizard hat in a magical forest..."
            )
            
            # é«˜ç´šè¨­å®š
            with st.expander("ğŸ”§ é«˜ç´šè¨­å®š"):
                col_size, col_num = st.columns(2)
                
                with col_size:
                    size_options = {
                        "1024x1024": "æ­£æ–¹å½¢ (1:1)",
                        "1152x896": "æ©«å‘ (4:3.5)", 
                        "896x1152": "ç›´å‘ (3.5:4)",
                        "1344x768": "å¯¬å± (16:9)",
                        "768x1344": "è¶…é«˜ (9:16)"
                    }
                    
                    selected_size = st.selectbox(
                        "åœ–åƒå°ºå¯¸",
                        options=list(size_options.keys()),
                        format_func=lambda x: f"{x} - {size_options[x]}",
                        index=0
                    )
                
                with col_num:
                    num_images = st.slider("ç”Ÿæˆæ•¸é‡", 1, 4, 1)
            
            # å¿«é€Ÿæç¤ºè©ï¼ˆæ ¹æ“šé¸ä¸­æ¨¡å‹æ¨è–¦ï¼‰
            st.subheader("ğŸ’¡ å¿«é€Ÿæç¤ºè©")
            
            # æ ¹æ“šæ¨¡å‹é¡å‹æ¨è–¦ä¸åŒçš„æç¤ºè©
            model_type = model_info.get('type', '')
            if 'å¿«é€Ÿ' in model_type:
                category_default = "äººç‰©è‚–åƒ"
            elif 'å‰µæ„' in model_type:
                category_default = "è—è¡“å‰µæ„"
            elif 'ç·¨è¼¯' in model_type:
                category_default = "ç§‘å¹»æœªä¾†"
            else:
                category_default = "è‡ªç„¶é¢¨æ™¯"
            
            prompt_categories = {
                "äººç‰©è‚–åƒ": [
                    "Professional headshot of a businesswoman in modern office",
                    "Portrait of an elderly man with wise eyes and gentle smile",
                    "Young artist with paint-splattered apron in studio"
                ],
                "è‡ªç„¶é¢¨æ™¯": [
                    "Sunset over snow-capped mountains with alpine lake",
                    "Tropical beach with crystal clear water and palm trees", 
                    "Autumn forest with golden leaves and morning mist"
                ],
                "ç§‘å¹»æœªä¾†": [
                    "Cyberpunk cityscape with neon lights and flying cars",
                    "Space station orbiting a distant planet",
                    "Robot assistant in a futuristic home"
                ],
                "è—è¡“å‰µæ„": [
                    "Abstract geometric composition with vibrant colors",
                    "Watercolor painting of blooming cherry blossoms",
                    "Digital art of a dragon made of flowing water"
                ]
            }
            
            category = st.selectbox(
                "é¸æ“‡é¡åˆ¥",
                list(prompt_categories.keys()),
                index=list(prompt_categories.keys()).index(category_default)
            )
            
            prompt_cols = st.columns(len(prompt_categories[category]))
            
            for i, quick_prompt in enumerate(prompt_categories[category]):
                with prompt_cols[i]:
                    if st.button(
                        quick_prompt[:30] + "...",
                        key=f"quick_{category}_{i}",
                        use_container_width=True,
                        help=quick_prompt
                    ):
                        st.session_state.quick_prompt = quick_prompt
                        st.rerun()
            
            if hasattr(st.session_state, 'quick_prompt'):
                prompt = st.session_state.quick_prompt
                delattr(st.session_state, 'quick_prompt')
            
            # ç”ŸæˆæŒ‰éˆ•ï¼ˆå¢å¼·ç‰ˆï¼‰
            generate_ready = (
                prompt.strip() and 
                api_configured and 
                (final_selected_model not in st.session_state.model_test_results or 
                 st.session_state.model_test_results[final_selected_model].get('available', True))
            )
            
            generate_btn = st.button(
                "ğŸš€ ç”Ÿæˆåœ–åƒ",
                type="primary",
                use_container_width=True,
                disabled=not generate_ready
            )
            
            # é¡¯ç¤ºç”Ÿæˆæº–å‚™ç‹€æ…‹
            if not generate_ready:
                if not prompt.strip():
                    st.warning("âš ï¸ è«‹è¼¸å…¥æç¤ºè©")
                elif not api_configured:
                    st.error("âŒ è«‹é…ç½® API å¯†é‘°")
                elif (final_selected_model in st.session_state.model_test_results and 
                      not st.session_state.model_test_results[final_selected_model].get('available', True)):
                    st.error("âŒ é¸ä¸­çš„æ¨¡å‹ä¸å¯ç”¨ï¼Œè«‹é¸æ“‡å…¶ä»–æ¨¡å‹æˆ–é‡æ–°æ¸¬è©¦")
        
        with col2:
            # API ç‹€æ…‹å’Œæ¨¡å‹ä¿¡æ¯
            if api_configured:
                provider_info = API_PROVIDERS.get(st.session_state.api_config['provider'], {})
                st.success(f"ğŸŸ¢ API å·²é€£æ¥\nä½¿ç”¨: {provider_info.get('name', 'Unknown')}")
            else:
                st.error("ğŸ”´ API æœªé…ç½®")
            
            # æ¨¡å‹æ¨è–¦é¢æ¿
            if api_configured:
                show_model_recommendations()
            
            st.subheader("ğŸ“‹ ä½¿ç”¨èªªæ˜")
            st.markdown(f"""
            **ç•¶å‰æ¨¡å‹:** {FLUX_MODELS[final_selected_model]['name']}
            
            **æ–°åŠŸèƒ½:**
            - ğŸ§ª æ¨¡å‹å¯ç”¨æ€§æ¸¬è©¦
            - ğŸ¯ æ™ºèƒ½æ¨¡å‹æ¨è–¦
            - âš¡ éŸ¿æ‡‰æ™‚é–“é¡¯ç¤º
            - ğŸ”„ è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
            
            **å»ºè­°æµç¨‹:**
            1. æ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§
            2. é¸æ“‡æ¨è–¦çš„æœ€ä½³æ¨¡å‹
            3. è¼¸å…¥è©³ç´°æç¤ºè©
            4. èª¿æ•´ç”Ÿæˆè¨­å®š
            5. é–‹å§‹ç”Ÿæˆ
            """)
            
            # çµ±è¨ˆä¿¡æ¯
            st.subheader("ğŸ“Š å¿«é€Ÿçµ±è¨ˆ")
            st.metric("ç¸½ç”Ÿæˆæ•¸", len(st.session_state.generation_history))
            st.metric("æ”¶è—æ•¸é‡", len(st.session_state.favorite_images))
            
            # æ¨¡å‹æ¸¬è©¦çµ±è¨ˆ
            if st.session_state.model_test_results:
                available_count = sum(1 for r in st.session_state.model_test_results.values() 
                                     if r.get('available', False))
                st.metric("å¯ç”¨æ¨¡å‹", f"{available_count}/{len(st.session_state.model_test_results)}")

        # åœ–åƒç”Ÿæˆé‚è¼¯ï¼ˆå¢å¼·ç‰ˆï¼‰
        if generate_btn and generate_ready:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {FLUX_MODELS[final_selected_model]['name']} ç”Ÿæˆåœ–åƒ..."):
                generation_params = {
                    "model": final_selected_model,
                    "prompt": prompt,
                    "n": num_images,
                    "size": selected_size
                }
                
                success, result = generate_images_with_retry(client, **generation_params)
                
                if success:
                    response = result
                    image_urls = [img.url for img in response.data]
                    metadata = {
                        "size": selected_size,
                        "num_images": num_images,
                        "model_info": FLUX_MODELS[final_selected_model],
                        "api_provider": st.session_state.api_config['provider'],
                        "success": True,
                        "response_time": st.session_state.model_test_results.get(
                            final_selected_model, {}
                        ).get('response_time', 0)
                    }
                    
                    add_to_history(prompt, final_selected_model, image_urls, metadata)
                    st.success(f"âœ¨ æˆåŠŸç”Ÿæˆ {len(response.data)} å¼µåœ–åƒï¼")
                    
                    # é¡¯ç¤ºåœ–åƒ
                    cols = st.columns(min(num_images, 2))
                    for i, image_data in enumerate(response.data):
                        with cols[i % len(cols)]:
                            st.subheader(f"åœ–åƒ {i+1}")
                            image_id = f"{len(st.session_state.generation_history)-1}_{i}"
                            display_image_with_actions(
                                image_data.url, 
                                image_id, 
                                st.session_state.generation_history[0]
                            )
                else:
                    st.error(f"âŒ ç”Ÿæˆå¤±æ•—: {result}")
                    # æ›´æ–°æ¨¡å‹ç‹€æ…‹
                    if final_selected_model in st.session_state.model_test_results:
                        st.session_state.model_test_results[final_selected_model]['available'] = False
                        st.session_state.model_test_results[final_selected_model]['error'] = result

# æ¨¡å‹æ¸¬è©¦é é¢ï¼ˆå…¨æ–°ï¼‰
with tab2:
    st.subheader("ğŸ§ª æ¨¡å‹å¯ç”¨æ€§æ¸¬è©¦")
    
    if not api_configured:
        st.warning("âš ï¸ è«‹å…ˆé…ç½® API å¯†é‘°")
        st.info("é…ç½®å®Œæˆå¾Œå³å¯æ¸¬è©¦æ¨¡å‹å¯ç”¨æ€§")
    else:
        # é¡¯ç¤ºæ¨¡å‹ç‹€æ…‹å„€è¡¨æ¿
        show_model_status_dashboard()

# å…¶ä»–æ¨™ç±¤é ä¿æŒåŸæœ‰åŠŸèƒ½...
# ï¼ˆé€™è£¡çœç•¥æ­·å²è¨˜éŒ„ã€æ”¶è—å¤¾ã€çµ±è¨ˆç­‰é é¢çš„ä»£ç¢¼ï¼Œå®ƒå€‘ä¿æŒä¸è®Šï¼‰

# æ­·å²è¨˜éŒ„é é¢
with tab3:
    st.subheader("ğŸ“š ç”Ÿæˆæ­·å²")
    # ... ä¿æŒåŸæœ‰ä»£ç¢¼ ...

# æ”¶è—å¤¾é é¢
with tab4:
    st.subheader("â­ æˆ‘çš„æ”¶è—")
    # ... ä¿æŒåŸæœ‰ä»£ç¢¼ ...

# çµ±è¨ˆé é¢
with tab5:
    st.subheader("ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
    # ... ä¿æŒåŸæœ‰ä»£ç¢¼ ...

# æ–°å¢å¹«åŠ©é é¢
with tab6:
    st.subheader("ğŸ’¡ ä½¿ç”¨å¹«åŠ©")
    
    st.markdown("### ğŸ¯ æ¨¡å‹æ¸¬è©¦åŠŸèƒ½")
    st.markdown("""
    **æ¨¡å‹æ¸¬è©¦çš„é‡è¦æ€§:**
    - ğŸ” ç¢ºèªæ¨¡å‹æ˜¯å¦å¯ç”¨
    - âš¡ æ¸¬é‡éŸ¿æ‡‰æ™‚é–“
    - ğŸ¯
